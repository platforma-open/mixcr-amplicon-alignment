ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
slices := import("@platforma-sdk/workflow-tengo:slices")
maps := import("@platforma-sdk/workflow-tengo:maps")
units := import("@platforma-sdk/workflow-tengo:units")
pt := import("@platforma-sdk/workflow-tengo:pt")
assets := import("@platforma-sdk/workflow-tengo:assets")
exec := import("@platforma-sdk/workflow-tengo:exec")
clonotypeLabel := import(":clonotype-label")

math := import("math")
json := import("json")

self.defineOutputs("tsv", "cdr3DistancesTsv")

cdr3DistanceSw := assets.importSoftware("@platforma-open/milaboratories.mixcr-amplicon-alignment.software:cdr3-distance-calculation")

self.body(func(inputs) {
	inputData := inputs[pConstants.VALUE_FIELD_NAME]
	inputDataMeta := inputData.getDataAsJson()

	ll.assert(inputDataMeta.keyLength == 1, "unexpected number of aggregation axes")

	params := inputs.params
	mainAbundanceColumnNormalized := params.mainAbundanceColumnNormalized
	mainAbundanceColumnUnnormalized := params.mainAbundanceColumnUnnormalized

	// { column: string; type: string }
	schemaPerClonotypeNoAggregates := params.schemaPerClonotypeNoAggregates
	schemaPerSample := params.schemaPerSample

	inputMap := inputData.inputs()
	numberOfSamples := len(inputMap)

	wf := pt.workflow().
		inMediumQueue().
		mem(int(math.max(numberOfSamples, 64)) * units.GB).
		cpu(int(math.max(numberOfSamples, 32)))

	dataFrames := []

	baseSchemaForRead := schemaPerSample + [ { column: "clonotypeKey", type: "String" } ]

	for sKey in maps.getKeys(inputMap) {
		inputFile := inputMap[sKey]
		key := json.decode(sKey)
		if len(key) != 1 {
			ll.panic("malformed key: %v", sKey)
		}
		sampleId := key[0]
		dfId := "table_" + sampleId

		df := wf.frame({
			file: inputFile,
			xsvType: "tsv",
			schema: baseSchemaForRead
		}, {
			id: dfId,
			inferSchema: false
		})
		dataFrames = append(dataFrames, df)
	}

	currentDf := undefined
	if len(dataFrames) == 0 {
		ll.panic("no input files found")
	} else if len(dataFrames) == 1 {
		currentDf = dataFrames[0]
	} else {
		currentDf = pt.concat(dataFrames)
	}

	aggExpressions := []

	for colDef in schemaPerClonotypeNoAggregates {
		if colDef.column == "clonotypeLabel" {
			continue
		}
		aggExpressions = append(aggExpressions,
			pt.col(colDef.column).maxBy(pt.col(mainAbundanceColumnNormalized)).alias(colDef.column)
		)
	}

	aggExpressions = append(aggExpressions,
		pt.col(mainAbundanceColumnNormalized).count().alias("sampleCount"),
		pt.col(mainAbundanceColumnUnnormalized).sum().alias(mainAbundanceColumnUnnormalized + "Sum"),
		pt.col(mainAbundanceColumnNormalized).mean().alias(mainAbundanceColumnNormalized + "Mean")
	)

	aggregatedDf := currentDf.groupBy("clonotypeKey").agg(aggExpressions...)

	aggregatedDf = clonotypeLabel.addClonotypeLabelColumnsPt(aggregatedDf, "clonotypeKey", "clonotypeLabel", pt)

	cdr3Df := aggregatedDf.select(
		pt.col("clonotypeKey"),
		pt.col("nSeqCDR3").alias("nSeqCDR3"),
		pt.col("aaSeqCDR3").alias("aaSeqCDR3")
	)

	aggregatedDf.save("output.tsv")
	cdr3Df.save("cdr3-sequences.tsv")

	ptablerResult := wf.run()

	processedTsv := ptablerResult.getFile("output.tsv")
	cdr3Tsv := ptablerResult.getFile("cdr3-sequences.tsv")
	cdr3DistancesTsv := undefined

	if !is_undefined(params.cdr3Sequences) {
		cdr3DistanceCmd := exec.builder().
			software(cdr3DistanceSw).
			mem("8GB").
			cpu(1).
			writeFile("cdr3-sequences.fasta", params.cdr3Sequences).saveFile("cdr3-sequences.fasta").
			arg("--tsv").arg("cdr3-sequences.tsv").addFile("cdr3-sequences.tsv", cdr3Tsv).
			arg("--ref-fasta").arg("cdr3-sequences.fasta").
			arg("--out").arg("cdr3-distances.tsv").saveFile("cdr3-distances.tsv")

		cdr3DistanceResult := cdr3DistanceCmd.run()
		cdr3DistancesTsv = cdr3DistanceResult.getFile("cdr3-distances.tsv")
	}

	return {
		tsv: processedTsv,
		cdr3DistancesTsv: cdr3DistancesTsv
	}
}) 